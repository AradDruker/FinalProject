{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "tensor([[[[0.2952]]]], grad_fn=<ConvolutionBackward0>)\n",
      "Average time taken for convolution on CPU: 42324.40 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Specify device as CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Define the input tensor (batch_size=1, channels=1, height=5, width=5)\n",
    "input_tensor = torch.randn(1, 1, 5, 5).to(device)\n",
    "\n",
    "# Define a convolutional layer with a 5x5 kernel and move it to the CPU\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=5, bias=False).to(device)\n",
    "\n",
    "# Warm-up (important to stabilize timings)\n",
    "for _ in range(10):\n",
    "    _ = conv_layer(input_tensor)\n",
    "\n",
    "# Run multiple iterations and measure time\n",
    "num_iterations = 1000\n",
    "start_time = time.time_ns()  # Start time in nanoseconds\n",
    "for _ in range(num_iterations):\n",
    "    output = conv_layer(input_tensor)\n",
    "end_time = time.time_ns()  # End time in nanoseconds\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time_ns = (end_time - start_time) / num_iterations  # Average time per iteration\n",
    "\n",
    "print(f\"Output:\\n{output}\")\n",
    "print(f\"Average time taken for convolution on CPU: {elapsed_time_ns:.2f} nanoseconds\")\n",
    "0.2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x5 Kernel Centered on First Pixel:\n",
      "tensor([[  0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0],\n",
      "        [  0,   0, 255, 255, 255],\n",
      "        [  0,   0, 255, 255, 255],\n",
      "        [  0,   0, 255, 255, 255]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Given 28x28 tensor (replace with your actual tensor)\n",
    "tensor_28x28 = torch.tensor([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
    "           255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
    "           255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
    "           255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
    "           211, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 136, 137,  54,\n",
    "           211, 138,  72, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 217,  59,  44,   7,\n",
    "            21,  11,   4,  11,  16,  16, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 170, 170,  59,   7,  15,\n",
    "            13,  53, 105,   2,   2,   8, 126, 210, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 152,  29,   0,  51, 161,\n",
    "           186, 186, 215, 125, 118,   8,  19,  57, 253, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 181,  37,   0,  65, 176,\n",
    "           252, 255, 224, 221, 188,  13,   7,   7, 154, 248, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 235,  85,  17,  35,  35, 126,\n",
    "           255, 255, 255, 255, 252,  71,  10,  27, 180, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 196,  84,   1,  40, 222,\n",
    "           254, 255, 255, 255, 250, 120,  26,  27, 123, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255,  84,  23,   7, 123,\n",
    "           199, 219, 251, 194,  67,  24,  14,  96,  96, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 244, 138,  46,   1,   7,\n",
    "            37,  95, 193,  77,  67,   7,  37, 102, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 235, 118, 164,  60,   1,   0,\n",
    "             0,  35,   6,   2,  16,  10,  85, 138, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 183, 116,  33,   4,  38,   9,   3,   0,\n",
    "             0,   0,   0,  10,  53, 162, 253, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 114,  45,   4,  20,  15,  76,  28, 115,\n",
    "           151,   0,   0,   1, 121, 224, 253, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255,  86,  86,  22,   0,  20,  96, 196, 177, 225,\n",
    "           235,  73,  17,   0,  68, 173, 251, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 112,  21,   0,  99, 183, 252, 252, 244, 255,\n",
    "           255, 213, 143,   0,   9,  54, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 186,  21,   0,  57, 210, 255, 255, 255, 255,\n",
    "           255, 230, 230,  52,   2,   9, 154, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 155,   9,   9,   0, 140, 200, 219, 255, 255,\n",
    "           255, 255, 167,  41,   0,  32, 222, 222, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255,  62,  22,  12,  73, 114, 222, 213, 213,\n",
    "           255, 229, 124,  56,   0,  29, 170, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 220, 148,  12,   5,   1, 121, 101,  51,\n",
    "           134,  50,   1,   1,   1,  29, 155, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255,  32,  32,   9,   1,   4,   7,\n",
    "            12,   1,   1,  17,  89, 194, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,  24,  50, 105,\n",
    "            16,  31,  16,  77, 186, 241, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 105,\n",
    "           180, 236, 185, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
    "           255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
    "           255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "          [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
    "           255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255]])\n",
    "\n",
    "# Step 1: Add padding of 2 to the tensor\n",
    "padded_tensor = F.pad(tensor_28x28, pad=(2, 2, 2, 2), mode='constant', value=0)\n",
    "\n",
    "# Step 2: Extract the 5x5 kernel around the first pixel\n",
    "# The first pixel (0, 0) in the original tensor corresponds to (2, 2) in the padded tensor\n",
    "kernel_5x5 = padded_tensor[0:5, 0:5]  # Centered at (2, 2) in padded tensor\n",
    "\n",
    "# Print the result\n",
    "print(\"5x5 Kernel Centered on First Pixel:\")\n",
    "print(kernel_5x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2A1ADF00F11C1222EAB30E461499E4F621EAC3FB030ADFCB360000183D channel: 1\n",
      "F4FCE010F3F3151F100C1110F70C11E51421162011EE0420E6FFFFFA7D channel: 2\n",
      "F1203746441A23563A232A2B0CFDFAE6E0C9B1AACFE89AA2EB00000B81 channel: 3\n",
      "F4AE8293CBEBC50EE5DC14391A2CF305403C310A23191E1C2E00000CD8 channel: 4\n",
      "FB1F162815CB210A2115D3A1E72BD6B0DE3134E4B117E0E80B000031CC channel: 5\n",
      "BBC6FE124A0DAEB2DD3C4122B1A0030D2424AABA27354A24D400002AD9 channel: 6\n"
     ]
    }
   ],
   "source": [
    "# Re-run the corrected script due to a reset in the execution environment\n",
    "\n",
    "def generate_coe_file_hex_with_padding(numbers, output_file):\n",
    "    \"\"\"\n",
    "    Generate a COE file with a concatenated hexadecimal number,\n",
    "    where each number is represented as an 8-bit signed binary value,\n",
    "    and the last number is a 32-bit signed binary value with padding in MSB and the value in the LSB.\n",
    "\n",
    "    Parameters:\n",
    "        numbers (list of int): The input array of signed numbers.\n",
    "        output_file (str): The name of the output COE file.\n",
    "    \"\"\"\n",
    "    if not isinstance(numbers, list) or not all(isinstance(n, int) for n in numbers):\n",
    "        raise ValueError(\"Input must be a list of signed integers.\")\n",
    "\n",
    "    if len(numbers) < 2:\n",
    "        raise ValueError(\"Input list must contain at least two numbers.\")\n",
    "\n",
    "    binary_values = []\n",
    "\n",
    "    # Process all numbers except the last as 8-bit signed binary\n",
    "    for num in numbers[:-1]:\n",
    "        if num < -128 or num > 127:\n",
    "            raise ValueError(f\"Number {num} exceeds the range of an 8-bit signed integer (-128 to 127).\")\n",
    "\n",
    "        # Convert to 8-bit signed binary (2's complement)\n",
    "        binary = f\"{num & 0xFF:08b}\"  # Mask with 0xFF to ensure 8 bits\n",
    "        binary_values.append(binary)\n",
    "\n",
    "    # Process the last number as 32-bit signed binary with MSB padding and LSB value\n",
    "    last_num = numbers[-1]\n",
    "    if last_num < -2**31 or last_num > 2**31 - 1:\n",
    "        raise ValueError(f\"Last number {last_num} exceeds the range of a 32-bit signed integer (-2^31 to 2^31-1).\")\n",
    "\n",
    "    # Convert to 32-bit signed binary (2's complement), right-aligned\n",
    "    last_binary = f\"{last_num & 0xFFFFFFFF:032b}\"  # Mask with 0xFFFFFFFF to ensure 32 bits\n",
    "\n",
    "    # Combine all binary values\n",
    "    concatenated_binary = \"\".join(binary_values) + last_binary\n",
    "\n",
    "    # Convert binary string to hexadecimal\n",
    "    concatenated_hex = f\"{int(concatenated_binary, 2):X}\".zfill(len(concatenated_binary) // 4)\n",
    "\n",
    "    # Write to COE file\n",
    "    # with open(output_file, \"w\") as coe_file:\n",
    "        # coe_file.write(\"memory_initialization_radix=16;\\n\")\n",
    "        # coe_file.write(\"memory_initialization_vector=\\n\")\n",
    "        # coe_file.write(f\"{concatenated_hex};\\n\")\n",
    "\n",
    "    return concatenated_hex\n",
    "\n",
    "# Input array of signed integers\n",
    "numbers_1 = [\n",
    "     42,   26,  -33,    0,  -15,   28,   18,   34,  -22,  -77,   14,   70,\n",
    "          20, -103,  -28,  -10,   33,  -22,  -61,   -5,    3,   10,  -33,  -53,\n",
    "          54, 6205  # Correctly handling the last number as 32-bit signed\n",
    "]\n",
    "\n",
    "numbers_2 = [\n",
    "    -12,  -4, -32,  16, -13, -13,  21,  31,  16,  12,  17,  16,  -9,  12,\n",
    "         17, -27,  20,  33,  22,  32,  17, -18,   4,  32, -26, -1411  # Correctly handling the last number as 32-bit signed\n",
    "]\n",
    "numbers_3 = [\n",
    "    -15,   32,   55,   70,   68,   26,   35,   86,   58,   35,   42,   43,\n",
    "          12,   -3,   -6,  -26,  -32,  -55,  -79,  -86,  -49,  -24, -102,  -94,\n",
    "         -21, 2945  # Correctly handling the last number as 32-bit signed\n",
    "]\n",
    "numbers_4 = [\n",
    "    -12,  -82, -126, -109,  -53,  -21,  -59,   14,  -27,  -36,   20,   57,\n",
    "          26,   44,  -13,    5,   64,   60,   49,   10,   35,   25,   30,   28,\n",
    "          46, 3288 # Correctly handling the last number as 32-bit signed\n",
    "]\n",
    "numbers_5 = [\n",
    "    -5,  31,  22,  40,  21, -53,  33,  10,  33,  21, -45, -95, -25,  43,\n",
    "        -42, -80, -34,  49,  52, -28, -79,  23, -32, -24,  11, 12748  # Correctly handling the last number as 32-bit signed\n",
    "]\n",
    "numbers_6 = [\n",
    "    -69, -58,  -2,  18,  74,  13, -82, -78, -35,  60,  65,  34, -79, -96,\n",
    "          3,  13,  36,  36, -86, -70,  39,  53,  74,  36, -44, 10969  # Correctly handling the last number as 32-bit signed\n",
    "]\n",
    "\n",
    "# Generate COE file in hexadecimal with the last number in the LSB and MSB padding\n",
    "print(f'{generate_coe_file_hex_with_padding(numbers_1, \"output_weights.coe\")} channel: 1')\n",
    "print(f'{generate_coe_file_hex_with_padding(numbers_2, \"output_weights.coe\")} channel: 2')\n",
    "print(f'{generate_coe_file_hex_with_padding(numbers_3, \"output_weights.coe\")} channel: 3')\n",
    "print(f'{generate_coe_file_hex_with_padding(numbers_4, \"output_weights.coe\")} channel: 4')\n",
    "print(f'{generate_coe_file_hex_with_padding(numbers_5, \"output_weights.coe\")} channel: 5')\n",
    "print(f'{generate_coe_file_hex_with_padding(numbers_6, \"output_weights.coe\")} channel: 6')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias quant (Quantized): 10969\n",
      "Convolution Result for Single Pixel:\n",
      "Output (With Bias): 21763.894862059133\n",
      "Quantized Output (8-bit): 41.56040293592159\n",
      "M scale: 0.0019096031845096618\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Quantized input tensor (5x5 region in uint8)\n",
    "input_tensor = torch.tensor([\n",
    "    [  0,   0,   0,   0, 0],\n",
    "    [ 0,   0,   0,   0, 0],\n",
    "    [   127,   127, 127,   0, 0],\n",
    "    [  127,   127, 127,   0, 0],\n",
    "    [127,   127, 127,   0, 0],\n",
    "], dtype=torch.uint8)  # Shape: (5, 5)\n",
    "\n",
    "# Quantized weights (5x5 kernel in int8)\n",
    "weights_tensor = torch.tensor([\n",
    "    [42,   26,  -33,    0,  -15],\n",
    "    [ 28,   18,   34,  -22,  -77],\n",
    "    [14,   70, 20, -103,  -28],\n",
    "    [  -10,   33,  -22,  -61,   -5],\n",
    "    [3,   10,  -33,  -53, 54],\n",
    "], dtype=torch.int8)  # Shape: (5, 5)\n",
    "\n",
    "# Quantization parameters\n",
    "input_scale = 0.0078\n",
    "input_zero_point = 127\n",
    "\n",
    "output_scale = 0.0186  # Scale for input activations\n",
    "output_zero_point = 0  # Zero-point for input activations\n",
    "\n",
    "weight_scale = 0.004553669132292271  # Scale for weights\n",
    "weight_zero_point = 0  # Zero-point for weights\n",
    "\n",
    "bias_float = 0.3896  # Bias in floating-point\n",
    "effective_scale = input_scale * weight_scale # Scale for the output\n",
    "bias_quant = (bias_float / effective_scale)# Bias in quantized form\n",
    "print(\"Bias quant (Quantized):\", round(bias_quant))\n",
    "\n",
    "# Step 2: Perform elementwise multiplication and summation\n",
    "conv_sum = torch.sum((input_tensor) * (weights_tensor - weight_zero_point)).item()\n",
    "\n",
    "# Step 3: Add the bias (in floating-point)\n",
    "conv_sum_with_bias = conv_sum + bias_quant\n",
    "\n",
    "# Step 4: Quantize the result back to 8-bit (uint8)\n",
    "M = effective_scale / output_scale\n",
    "output_quantized = output_zero_point + M * conv_sum_with_bias\n",
    "\n",
    "# Step 5: Clamp to the valid uint8 range [0, 255]s\n",
    "output_quantized = max(0, min(255, output_quantized))\n",
    "\n",
    "# Display results\n",
    "print(\"Convolution Result for Single Pixel:\")\n",
    "print(\"Output (With Bias):\", conv_sum_with_bias)\n",
    "print(\"Quantized Output (8-bit):\", output_quantized)\n",
    "print(\"M scale:\", M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 Output:\n",
      "[0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 51, 87]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 51]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 4, 7, 8, 0, 0, 0, 0, 0, 0, 0, 8, 11, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 2, 7, 9, 11, 22, 35, 40, 0, 0, 0, 0, 0, 1, 5, 0, 1, 12, 32, 14, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 7, 16, 25, 38, 81, 100, 13, 0, 0, 0, 0, 0, 0, 0, 0, 40, 79, 41, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 20, 94, 127, 22, 0, 0, 0, 0, 0, 0, 0, 0, 42, 79, 37, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 87, 112, 15, 0, 0, 0, 0, 0, 0, 0, 0, 16, 42, 19, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 87, 85, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 20, 4, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 37, 77, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 20]\n",
      "[9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 49, 26, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 27, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 33, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 41, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 53, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 73, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 99, 31, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0]\n",
      "[0, 0, 25, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 68, 104, 38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15]\n",
      "[0, 0, 12, 48, 58, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 103, 63, 0, 0, 0, 0, 0, 0, 0, 4, 39]\n",
      "[0, 0, 0, 12, 58, 58, 35, 0, 0, 0, 0, 12, 10, 0, 0, 0, 0, 38, 89, 83, 27, 0, 0, 0, 0, 0, 2, 49]\n",
      "[0, 0, 0, 0, 7, 38, 38, 18, 2, 4, 7, 14, 6, 0, 0, 0, 0, 0, 6, 60, 67, 30, 0, 0, 0, 0, 10, 40]\n",
      "[0, 0, 0, 0, 0, 0, 0, 8, 15, 16, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 24, 26, 19, 17, 9, 0, 23]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 10, 5, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Maxpooled Output:\n",
      "[0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 87]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20]\n",
      "[0, 7, 11, 35, 40, 0, 0, 11, 1, 32, 14, 0, 0, 20]\n",
      "[0, 0, 16, 38, 100, 127, 0, 0, 0, 40, 79, 37, 0, 20]\n",
      "[0, 1, 0, 0, 0, 112, 85, 0, 0, 0, 16, 42, 4, 20]\n",
      "[9, 0, 0, 0, 0, 37, 77, 2, 0, 0, 0, 0, 1, 20]\n",
      "[4, 1, 0, 0, 0, 0, 33, 7, 0, 0, 0, 0, 0, 20]\n",
      "[0, 0, 0, 0, 0, 4, 53, 20, 0, 0, 0, 0, 0, 19]\n",
      "[0, 0, 0, 0, 0, 0, 35, 73, 0, 0, 0, 0, 0, 13]\n",
      "[0, 25, 0, 0, 0, 0, 0, 99, 104, 0, 0, 4, 0, 15]\n",
      "[0, 48, 58, 35, 0, 12, 10, 0, 103, 89, 27, 0, 0, 49]\n",
      "[0, 0, 38, 38, 16, 14, 6, 0, 0, 60, 67, 26, 17, 40]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 5, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aradd\\AppData\\Local\\Temp\\ipykernel_32392\\261083267.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  maxpooled_output = torch.tensor(maxpooled_output, dtype=torch.float).view(14,14)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example usage\n",
    "input_matrix = torch.tensor([\n",
    "    [254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[254, 254, 237, 221, 221, 221, 221, 223, 248, 254, 254, 254, 254, 254, 254, 254, 246, 221, 221, 221, 236, 254, 254, 254, 254, 254, 254, 254],\n",
    "[253, 235, 100, 108, 124, 124, 124, 127, 153, 171, 244, 253, 254, 253, 254, 253, 149, 86, 125, 124, 142, 234, 252, 252, 254, 254, 254, 254],\n",
    "[254, 135, 191, 242, 253, 253, 253, 249, 203, 99, 118, 242, 252, 253, 253, 230, 115, 229, 254, 253, 224, 150, 234, 253, 254, 254, 254, 254],\n",
    "[197, 155, 249, 253, 253, 253, 253, 254, 253, 234, 103, 122, 245, 253, 251, 149, 201, 253, 253, 253, 252, 224, 142, 235, 254, 254, 254, 254],\n",
    "[137, 207, 253, 253, 253, 254, 253, 254, 253, 253, 236, 98, 165, 254, 221, 132, 244, 252, 254, 254, 253, 254, 162, 229, 254, 254, 254, 254],\n",
    "[105, 254, 253, 253, 253, 254, 254, 254, 254, 253, 254, 236, 136, 227, 213, 128, 253, 253, 253, 254, 254, 254, 254, 253, 254, 254, 254, 254],\n",
    "[105, 253, 254, 254, 253, 254, 254, 254, 254, 254, 253, 253, 171, 175, 160, 121, 253, 253, 254, 253, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[105, 254, 254, 253, 253, 254, 254, 254, 254, 254, 253, 253, 232, 118, 109, 205, 253, 253, 253, 253, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[191, 254, 254, 253, 253, 254, 254, 254, 254, 254, 253, 253, 232, 118, 118, 232, 253, 253, 253, 253, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[253, 254, 254, 254, 253, 254, 254, 254, 254, 254, 253, 253, 233, 118, 119, 233, 253, 253, 253, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[253, 253, 254, 253, 254, 254, 254, 254, 254, 254, 253, 253, 233, 118, 118, 233, 253, 253, 253, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[253, 253, 254, 253, 253, 254, 253, 254, 254, 254, 253, 254, 232, 119, 118, 233, 253, 253, 253, 253, 254, 254, 254, 254, 254, 253, 253, 254],\n",
    "[253, 253, 254, 253, 253, 253, 253, 253, 253, 254, 253, 254, 151, 193, 140, 211, 253, 253, 253, 253, 254, 254, 254, 254, 254, 254, 253, 253],\n",
    "[254, 254, 253, 253, 253, 253, 253, 253, 253, 252, 253, 247, 131, 217, 213, 119, 248, 253, 253, 253, 254, 254, 254, 254, 254, 253, 253, 253],\n",
    "[253, 253, 253, 253, 243, 211, 253, 253, 253, 252, 253, 162, 144, 248, 226, 78, 162, 253, 253, 253, 254, 254, 254, 254, 254, 253, 232, 219],\n",
    "[253, 254, 253, 242, 157, 201, 254, 253, 253, 247, 161, 157, 223, 253, 254, 223, 157, 161, 248, 253, 254, 254, 254, 254, 246, 149, 125, 143],\n",
    "[253, 253, 248, 131, 93, 179, 248, 248, 217, 143, 127, 223, 253, 254, 253, 254, 223, 127, 143, 217, 251, 254, 252, 248, 151, 79, 219, 244],\n",
    "[253, 253, 251, 213, 185, 96, 112, 112, 139, 211, 248, 254, 253, 254, 254, 252, 252, 248, 209, 128, 121, 193, 179, 91, 179, 227, 253, 252],\n",
    "[252, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 254, 253, 253, 253, 253, 253, 237, 165, 157, 158, 191, 253, 254, 254, 253],\n",
    "[253, 254, 254, 253, 254, 254, 254, 254, 253, 253, 253, 253, 254, 253, 253, 253, 253, 253, 253, 254, 254, 254, 254, 254, 253, 254, 253, 254],\n",
    "[253, 253, 253, 253, 253, 253, 254, 254, 253, 253, 253, 254, 253, 253, 254, 254, 253, 253, 253, 253, 254, 254, 253, 253, 253, 254, 253, 253],\n",
    "[254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254],\n",
    "[254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254]\n",
    "] ,dtype=torch.uint8)\n",
    "\n",
    "# Quantized weights (5x5 kernel in int8)\n",
    "kernel_weights = torch.tensor([\n",
    "    [-69, -58,  -2,  18,  74],\n",
    "    [  13, -82, -78, -35,  60],\n",
    "    [65,  34, -79, -96, 3],\n",
    "    [ 13,  36,  36, -86, -70],\n",
    "    [39,  53,  74,  36, -44]\n",
    "], dtype=torch.int8)  # Shape: (5, 5)\n",
    "\n",
    "\n",
    "# Process the matrix to set values under 128 to 0 and subtract 127 if greater than 127\n",
    "processed_matrix = torch.where(input_matrix > 127, input_matrix - 127, torch.zeros_like(input_matrix))\n",
    "# print(processed_matrix)\n",
    "\n",
    "# Add padding of 2 to the tensor\n",
    "padded_tensor = F.pad(processed_matrix, pad=(2, 2, 2, 2), mode='constant', value=0)\n",
    "\n",
    "\n",
    "# Extract the 5x5 kernel around the first pixel\n",
    "image_slice = padded_tensor[5:10, 5:10]   # Centered at (2, 2) in padded tensor\n",
    "# print(\" image_slice:\", image_slice)\n",
    "\n",
    "# Perform the element-wise multiplication and summation\n",
    "results = []\n",
    "\n",
    "# Loop over every possible position of the 5x5 kernel within the padded tensor\n",
    "for i in range(28):  # Vertical index for the original 28x28 area\n",
    "    for j in range(28):  # Horizontal index for the original 28x28 area\n",
    "        # Extract the 5x5 region corresponding to this position\n",
    "        image_slice = padded_tensor[i:i+5, j:j+5]\n",
    "\n",
    "        # Perform the element-wise multiplication and summation\n",
    "        result_matrix = torch.sum(image_slice * kernel_weights).item()\n",
    "\n",
    "        # Example bias and multiplication constant for further processing\n",
    "        bias = 6205\n",
    "        M = 0.0019096031845096618\n",
    "        final_result = (result_matrix + bias) * M\n",
    "\n",
    "        # Clamp to max 255 and round the result\n",
    "        final_clamped = torch.clamp(torch.tensor(final_result), min=0, max=255).item()\n",
    "        final_rounded = round(final_clamped)\n",
    "\n",
    "        # Append the rounded result to the results list\n",
    "        results.append(final_rounded)\n",
    "\n",
    "# Check the results\n",
    "# print(\"Results length:\", len(results))\n",
    "print(\"Conv1 Output:\")\n",
    "for i in range(0,28):\n",
    "    print( results[i*28:i*28+28])\n",
    "\n",
    "\n",
    "result_tensor = torch.tensor(results, dtype=torch.float).view(28, 28)\n",
    "# print(result_tensor)\n",
    "\n",
    "# Max pooling operation\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "maxpooled_output = maxpool(result_tensor.unsqueeze(0).unsqueeze(0))  # Add batch and channel dimensions\n",
    "\n",
    "maxpooled_output = torch.tensor(maxpooled_output, dtype=torch.float).view(14,14)\n",
    "\n",
    "# Assuming maxpooled_output is already a tensor shaped as [14, 14] from the previous operations\n",
    "print(\"Maxpooled Output:\")\n",
    "for row in maxpooled_output:\n",
    "    # Convert each tensor element to an integer and list it\n",
    "    print([int(x) for x in row.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
